{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains a minimalist template for logging nested hyperparameter tuning runs in Databricks using hyperopt and mlflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# set the path where the best params can be saved in one seperate files, can be helpful when you have multiple layers in a nested tuning design\n",
    "# but check out mlflow.search_runs() for simpler designs where you can search all runs under one experiment_id\n",
    "model_best_params_path = f\"\"\"{project_dbfs_path}/HM_best_params.pkl\"\"\"\n",
    "\n",
    "# Define the search space\n",
    "hyp_params = {\n",
    "            'l1_ratio':                hp.choice('l1_ratio', np.arange(0, 1.0, 0.1))\n",
    "        }\n",
    "fit_params = {\n",
    "            'early_stopping_rounds':   hp.choice('early_stopping_rounds', [10,20]),\n",
    "}\n",
    "\n",
    "space = dict()\n",
    "space['hyp_params'] = hyp_params\n",
    "space['fit_params'] = fit_params\n",
    "\n",
    "# or use SparkTrails() to speed things up\n",
    "trials = Trials()\n",
    "\n",
    "# set up the tuning\n",
    "def tune_model(space, model, X, y, max_evals, patience):    \n",
    "   \n",
    "    # define the loss function\n",
    "    def loss_function(space, scorer=scorer, X=X, y=y):\n",
    "     \n",
    "        with mlflow.start_run(nested = True):\n",
    "\n",
    "            # configure the run\n",
    "            hyp_params = space['hyp_params'] \n",
    "            fit_params = space['fit_params']                  \n",
    "            model.train(X,y, **hyp_params, **fit_params)\n",
    "            \n",
    "            # get model performance (could be a custom function)\n",
    "            cv_results = model.cross_validate(X, y)\n",
    "\n",
    "            # log params and metrics for comparison\n",
    "            mlflow.sklearn.log_model(model, \"model\")             \n",
    "            auc = np.mean(cv_results['auc'])\n",
    "            mlflow.log_metric('cv_auc', auc)\n",
    "            mlflow.log_params(hyp_params)\n",
    "            mlflow.log_params(fit_params)\n",
    "                        \n",
    "            # optimize auc\n",
    "            loss = 1 - auc\n",
    "\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    # all experiments will be nested under the run_name\n",
    "    with mlflow.start_run(run_name = 'Model turning'):\n",
    "        best=fmin(\n",
    "            fn = loss_function,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = max_evals,\n",
    "            trials=trials,\n",
    "            rstate = np.random.default_rng(10),\n",
    "            early_stop_fn=no_progress_loss(patience)\n",
    "        )\n",
    "    \n",
    "    pickle.dump(best, open(model_best_params_path, 'wb'))    \n",
    "\n",
    "    return best\n",
    "\n",
    "# configure then run the tuning\n",
    "max_evals = 400\n",
    "patience = 50\n",
    "tune_model(space, model, X, y, max_evals, patience)\n",
    "\n",
    "# retrieve the best params from tuning\n",
    "best = pickle.load(open(model_best_params_path), 'rb')\n",
    "best_space = space_eval(space, best)\n",
    "\n",
    "# utilize the best params to train the best model\n",
    "model.train(X,y, **best_space['hyp_params'], **best_space['fit_params'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
