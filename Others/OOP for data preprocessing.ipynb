{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP for Data Preprocessing\n",
    "\n",
    "Last time when I played with OOP for ML, I created a all-in-one classifier that can train, tune and explain multiple ML algorithms ([notebook here](https://github.com/MenaWANG/ML_toy_examples/blob/main/modeling%20algorithm/OOP%20and%20multiple%20models.ipynb))\n",
    "\n",
    "But at the end of the above note, I have also discussed the option of smaller subclass following the **Single Responsibility** principle in SOLID. Therefore, this time as an experiment, I hope to create a smaller custom class just for data preprocessing.\n",
    "\n",
    "One interesting technical challenge is how to give meaningful names to the OneHotEncoded columns, and how to do it when one reference categories is dropped. Please see the solution in the class and also with more details in the Appendix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_preprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column_transformer = None):\n",
    "        self.column_transformer = None\n",
    "    \n",
    "    def get_column_names(self, X):\n",
    "        transformed_cols = []\n",
    "\n",
    "        if self.numeric_columns:\n",
    "            transformed_cols += self.numeric_columns\n",
    "        if self.categorical_columns:\n",
    "            encoder = self.column_transformer.named_transformers_['cat']['encoder']\n",
    "            categorical_values = encoder.categories_\n",
    "            for col, values in zip(self.categorical_columns, categorical_values):\n",
    "                transformed_cols += [f'{col}_{val}' for val in values]\n",
    "                # transformed_cols += [f'{col}_{val}' for val in values[1:]]  # Exclude the first value\n",
    "\n",
    "        return transformed_cols\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.numeric_columns = X.select_dtypes(include = np.number).columns.tolist()\n",
    "        self.categorical_columns = X.select_dtypes(exclude = np.number).columns.tolist()\n",
    "        \n",
    "        if self.numeric_columns:\n",
    "            num_transformer = Pipeline(steps = [\n",
    "                ('imputer', SimpleImputer(strategy = 'mean')),\n",
    "                ('scaler', StandardScaler(with_mean = True, with_std = True)),\n",
    "            ]) \n",
    "        \n",
    "        if self.categorical_columns:\n",
    "            cat_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy = 'most_frequent', keep_empty_features = False)),\n",
    "                ('encoder', OneHotEncoder()),\n",
    "                #('encoder', OneHotEncoder(drop = 'first')), # Drop the first as reference category\n",
    "            ])\n",
    "        \n",
    "        self.column_transformer = ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('num', num_transformer, self.numeric_columns),\n",
    "                ('cat', cat_transformer, self.categorical_columns),\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )\n",
    "        \n",
    "        self.column_transformer.fit(X)\n",
    "\n",
    "        # Get the column names after transformation\n",
    "        self.column_names = self.get_column_names(X)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not self.column_transformer:\n",
    "            raise ValueError('The preprocessor has not been fit yet')\n",
    "        \n",
    "        return pd.DataFrame(self.column_transformer.transform(X), columns=self.column_names)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo data before preprocessing\n",
      "     age   income  gender education\n",
      "0  30.0  50000.0    Male  Bachelor\n",
      "1   NaN  60000.0  Female       NaN\n",
      "2  35.0  75000.0     NaN       PhD\n",
      "3  28.0  70000.0    Male  Bachelor\n",
      "4  30.0      NaN    Male    Master\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform demo data\n",
    "data = pd.DataFrame({\n",
    "    'age': [30, np.nan, 35, 28, 30],\n",
    "    'income': [50000, 60000, 75000, 70000, np.nan],\n",
    "    'gender': ['Male', 'Female', np.nan, 'Male', 'Male'],\n",
    "    'education': ['Bachelor', np.nan, 'PhD', 'Bachelor', 'Master'], \n",
    "})\n",
    "\n",
    "print(\"Demo data before preprocessing\\n\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo data after preprocessing\n",
      "         age    income  gender_Male  education_Master  education_PhD\n",
      "0 -0.324253 -1.601112          1.0               0.0            0.0\n",
      "1  0.000000 -0.436667          0.0               0.0            0.0\n",
      "2  1.837435  1.310001          1.0               0.0            1.0\n",
      "3 -1.188929  0.727778          1.0               0.0            0.0\n",
      "4 -0.324253  0.000000          1.0               1.0            0.0\n"
     ]
    }
   ],
   "source": [
    "preprocessor = custom_preprocessor()\n",
    "preprocessor.fit(data)\n",
    "data_preprocessed = pd.DataFrame(preprocessor.transform(data))\n",
    "print(\"Demo data after preprocessing\\n\", data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "In the above class, we leveraged `Pipeline()` and `ColumnTransformer()` to create steps to preprocess numeric and categorical data, respectively. \n",
    "\n",
    "One interesting consideration regarding the steps is whether to impute before or after scaling. As a simple demo, I did the imputation first then the scaling for both numeric and categorical features. But for numeric variables, one would need to weight the pro and con of these two alternatives for each specific project based on particulars such as the imputation algorithm used and the distribution of the feature being imputed. (Quite some discussions we can find online, here is [one example](https://stats.stackexchange.com/questions/138203/imputation-of-missing-data-before-or-after-centering-and-scaling#:~:text=It%20really%20depends%20on%20the,lower%20magnitude%20values%20converge%20faster.))\n",
    "\n",
    "Another thing to consider is the condition before imputation. If a feature has 25% of missing values, do we still impute them, how about 50% missing? With a custom class like this, we can easily incorporate our threshold into the custom preprocessor. In the same token, any specific logic can be easily added to the custom preprocessor and we will only need to maintian and update these rules in one place. This is one big advantage of the OOP (vs functional) approach for such usage cases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix and Tests\n",
    "\n",
    "### Drop one category in OneHotEncoding\n",
    "\n",
    "Above in the class definition, we have commented out code which allow us to drop the first category of each categorical variable. This is useful when we work with ML algorithms that are sensitive to multicollinearity (e.g., linear and logistic regressions), but not as big a deal for algorithms that are less affected by multicollinearity (e.g., tree-based algorithms and neural networks). \n",
    "\n",
    "Below are the code to quickly test how the result differ whether a reference category is dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_encode(data: pd.DataFrame, drop_first: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"This function encode input df with one-hot-encoding and return a encoded df. \n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): a DataFrame to be encoded.\n",
    "        drop_first (bool, optional): whether to drop the first category as the reference category. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the encoded DataFrame. \n",
    "    \"\"\"\n",
    "    # Columns to be one-hot encoded\n",
    "    categorical_cols = data.columns\n",
    "\n",
    "    # Create an instance of OneHotEncoder\n",
    "    if drop_first:\n",
    "        encoder = OneHotEncoder(drop = 'first')\n",
    "    else:\n",
    "        encoder = OneHotEncoder()\n",
    "\n",
    "    # Fit and transform the data\n",
    "    encoded_data = encoder.fit_transform(data[categorical_cols])\n",
    "    # Get the unique category values\n",
    "    unique_categories = encoder.categories_\n",
    "    print(unique_categories)\n",
    "\n",
    "    # Generate column names for the encoded features\n",
    "    if drop_first:\n",
    "        column_names = [f'{col}_{category}' for col, categories in zip(categorical_cols, unique_categories) for category in categories[1:]]\n",
    "    else:\n",
    "        column_names = [f'{col}_{category}' for col, categories in zip(categorical_cols, unique_categories) for category in categories]\n",
    "\n",
    "    # Convert the result to a dense array for visualization\n",
    "    encoded_array = encoded_data.toarray()\n",
    "\n",
    "    # Create a DataFrame with dynamically generated column names\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=column_names)\n",
    "\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data as a DataFrame\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green', 'Red', 'Blue'],\n",
    "                     'Size': ['Large', 'Medium', 'Large', 'Small', 'Medium']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Blue', 'Green', 'Red'], dtype=object), array(['Large', 'Medium', 'Small'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Size_Medium</th>\n",
       "      <th>Size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color_Green  Color_Red  Size_Medium  Size_Small\n",
       "0          0.0        1.0          0.0         0.0\n",
       "1          0.0        0.0          1.0         0.0\n",
       "2          1.0        0.0          0.0         0.0\n",
       "3          0.0        1.0          0.0         1.0\n",
       "4          0.0        0.0          1.0         0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_encode(data, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Size_Large</th>\n",
       "      <th>Size_Medium</th>\n",
       "      <th>Size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color_Blue  Color_Green  Color_Red  Size_Large  Size_Medium  Size_Small\n",
       "0         0.0          0.0        1.0         1.0          0.0         0.0\n",
       "1         1.0          0.0        0.0         0.0          1.0         0.0\n",
       "2         0.0          1.0        0.0         1.0          0.0         0.0\n",
       "3         0.0          0.0        1.0         0.0          0.0         1.0\n",
       "4         1.0          0.0        0.0         0.0          1.0         0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_encode(data, drop_first = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
