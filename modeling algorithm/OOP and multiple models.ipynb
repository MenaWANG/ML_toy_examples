{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "During my Python learning journey, one thing really delights me is how easy it is to use Object Oriented Programming to modulize code, make it easy to test, extend, reuse and maintain. Below is a toy example where I created one classifier class to train and tune three classification models (svm, RandomForest & XGBoost).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import hp, fmin, space_eval, tpe, Trials\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the class for multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the class\n",
    "class Classifier:\n",
    "    def __init__(self, X, y, model_type, space, n_splits, seed):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_splits = n_splits\n",
    "        self.seed = seed\n",
    "        self.space = space\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def objective(self, space):\n",
    "        if self.model_type == 'svm':\n",
    "             model = SVC(**space)\n",
    "        elif self.model_type == 'randomforest':\n",
    "            model = RandomForestClassifier(**space)\n",
    "        elif self.model_type == 'xgboost':\n",
    "            model = XGBClassifier(**space)\n",
    "        else:\n",
    "            print('model not available yet')        \n",
    "\n",
    "        cv_scores = cross_val_score(model, self.X, self.y, cv=self.n_splits, scoring='roc_auc', n_jobs=-1)\n",
    "        return 1 - cv_scores.mean()\n",
    "    \n",
    "    def optimize(self, max_evals=10):\n",
    "        best = fmin(fn=self.objective, space=self.space, algo=tpe.suggest, trials = trials, \n",
    "                    max_evals=max_evals, rstate=np.random.default_rng(self.seed))\n",
    "        return best    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the hyperparameter search space for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up space for hyperparameter tuning\n",
    "xgb_params = {\n",
    "    'max_depth':         hp.choice('max_depth',          np.arange(1, 4, 1, dtype=int)),\n",
    "    'min_child_weight':  hp.quniform('min_child_weight', 1, 7, 1),\n",
    "    'gamma':             hp.uniform('gamma', 0, 0.4),\n",
    "    'subsample':         hp.choice('subsample', [0.6, 0.8]),\n",
    "    'colsample_bytree':  hp.choice('colsample_bytree', [0.6, 0.8]),\n",
    "    'learning_rate':     hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators':      hp.choice('n_estimators',       np.arange(50, 200, 50, dtype =int)),\n",
    "    'scale_pos_weight':  hp.quniform('scale_pos_weight', 1, 16, 1),\n",
    "    'reg_alpha':         hp.uniform('reg_alpha', 0, 0.4),\n",
    "    'reg_lambda':        hp.uniform('reg_lambda', 0, 0.4),\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\":      hp.choice('n_estimators',        np.arange(50, 200, 50, dtype =int)),\n",
    "    'max_depth':         hp.choice('max_depth',           np.arange(3, 6, 1, dtype=int)),\n",
    "    'min_samples_split': hp.choice('min_samples_split',   np.arange(2, 20, 1, dtype=int)),\n",
    "    'min_samples_leaf':  hp.choice('min_samples_leaf',    np.arange(2, 20, 1, dtype=int)),\n",
    "    'max_features':      hp.choice('max_features', ['auto', 'sqrt']),\n",
    "    'criterion':         hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'kernel':            hp.choice('kernel', ['linear', 'rbf']),\n",
    "    'C':                 hp.choice('C', [0.1, 1, 10])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data (minimal process)\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss: 0.046052631578947456\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "baseline_model = RandomForestClassifier()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "baseline_auc = roc_auc_score(y_pred, y_test)\n",
    "print('baseline loss:', 1 - baseline_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now play with the Classifier defined above. Train and tune any of the three classification algorithms and see which one performs the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 50/50 [00:30<00:00,  1.65trial/s, best loss: 0.008462332301341524]\n",
      "CPU times: total: 2.41 s\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model = Classifier(X_train, y_train, model_type = 'randomforest', space = rf_params, n_splits = 5, seed=123)\n",
    "trials = Trials()\n",
    "best = model.optimize(max_evals=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "The tuned RandomForest model has much lower loss than the baseline one. It is super easy to define another model to check out is performance as well. Please see below, the tuned svm classifier performed even better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 50/50 [00:01<00:00, 25.83trial/s, best loss: 0.0066047471620226395]\n",
      "CPU times: total: 1.41 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model = Classifier(X_train, y_train, model_type = 'svm', space = svm_params, n_splits = 5, seed=123)\n",
    "trials = Trials()\n",
    "best = model.optimize(max_evals=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some final notes\n",
    "If none of the hyperparamters across models have the same name (say if we only have svm and randomforest to test), we could create a params dictionary and just pass the whole dictionary when defining the model later (demo code below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "space = dict()\n",
    "space['svm_params'] = svm_params\n",
    "space['rf_params']  = rf_params\n",
    "\n",
    "# in objective()\n",
    "model = SVC(**space['svm_params'])\n",
    "model = RandomForestClassifier(**space['rf_params'])\n",
    "\n",
    "# when defining the model\n",
    "model = Classifier(X_train, y_train, model_type= 'randomforest', space=params, n_splits=5, seed=123)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38-modelling]",
   "language": "python",
   "name": "conda-env-py38-modelling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
