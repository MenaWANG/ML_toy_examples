{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "During my Python learning journey, one thing really delights me is how easy it is to use Object Oriented Programming to modulize code, make it easy to test, extend, reuse and maintain. Below is a toy example where I created one classifier class to train and tune three classification models (svm, RandomForest & XGBoost).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import hp, fmin, space_eval, tpe, Trials\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the class for multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the class\n",
    "class Classifier:\n",
    "    def __init__(self, X, y, model_type, space, n_splits, seed):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_splits = n_splits\n",
    "        self.seed = seed\n",
    "        self.space = space\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def objective(self, space):\n",
    "        if self.model_type == 'svm':\n",
    "            model = SVC(**space)\n",
    "        elif self.model_type == 'randomforest':\n",
    "            model = RandomForestClassifier(**space)\n",
    "        elif self.model_type == 'xgboost':\n",
    "            model = XGBClassifier(**space)\n",
    "        else:\n",
    "            print('model not available yet')\n",
    "\n",
    "        cv_scores = cross_val_score(model, self.X, self.y, cv=self.n_splits, scoring='roc_auc', n_jobs=-1)\n",
    "        return 1 - cv_scores.mean()\n",
    "    \n",
    "    def optimize(self, max_evals=10):\n",
    "        best = fmin(fn=self.objective, space=self.space, algo=tpe.suggest, trials = trials, \n",
    "                    max_evals=max_evals, rstate=np.random.default_rng(self.seed))\n",
    "        return best        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the hyperparameter search space for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up space for hyperparameter tuning\n",
    "xgb_params = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(1, 4, 1, dtype=int)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 7, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.4),\n",
    "    'subsample': hp.choice('subsample', [0.6, 0.8]),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', [0.6, 0.8]),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(50, 200, 50, dtype =int)),\n",
    "    'scale_pos_weight': hp.quniform('scale_pos_weight', 1, 16, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 0.4),\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": hp.choice('n_estimators', np.arange(50, 200, 50, dtype =int)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3,6,1, dtype=int)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', np.arange(2, 20, 1, dtype=int)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(2, 20, 1, dtype=int)),\n",
    "    'max_features': hp.choice('max_features', ['auto', 'sqrt']),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'kernel': hp.choice('kernel', ['linear', 'rbf']),\n",
    "    'C': hp.choice('C', [0.1, 1, 10])    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data (minimal process)\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss: 0.046052631578947456\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "baseline_model = RandomForestClassifier()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "baseline_auc = roc_auc_score(y_pred, y_test)\n",
    "print('baseline loss:', 1 - baseline_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now play with the Classifier defined above. Train and tune any of the three classification algorithms and see which one performs the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, to train and tune the randomforest model: \n",
    "model = Classifier(X_train, y_train, model_type= 'randomforest', space=rf_params, n_splits=5, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 100/100 [00:42<00:00,  2.34trial/s, best loss: 0.007946336429308531]\n",
      "CPU times: total: 3.42 s\n",
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "trials = Trials()\n",
    "\n",
    "best = model.optimize(max_evals=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38-modelling]",
   "language": "python",
   "name": "conda-env-py38-modelling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
