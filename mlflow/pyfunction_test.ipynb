{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm-Agnostic Model Deployment with Mlflow\n",
    "\n",
    "One common challenge in MLOps is the need to migrate between various estimators or algorithms to achieve the optimal solution for a business problem.\n",
    "\n",
    "Consider a scenario where we had a scikit-learn (sklearn) model deployed in production for a specific use case. Later, we discovered that a deep learning model performed even better. In such a scenario, if the sklearn model was deployed in its native flavour, the switch to deep learning model could be a hassle because the two model artifacts are very different.\n",
    "\n",
    "## MLflow pyfunc flavor\n",
    "\n",
    "The `mlflow.pyfunc` model flavor offers a generic way of model building. It can serve as a unified, default model interface for all MLflow Python models, regardless of which persistence library, module or framework was used to produce the model. With pyfunc, we can deploy a python function without worrying about the underlying format of the model. Thanks to its unified model representations, pyfunc massively reduces the complexity of model deployment, redeployment and downstream scoring. \n",
    "\n",
    "What's more, this means that, not only the model, but also the full pipeline, encompassing elements such as pre- and post-processing steps or any arbitrary code we would like to execute during model loading, can all be encapsulated within the pyfunc object that works seamlessly with the rest of the mlflow ecosystem. \n",
    "\n",
    "Last but not least, pyfunc enable us to package the trained model pipeline in a platform-agnostic manner, which provides optimal flexibility in deployment options and facilitates model reuse across diverse platforms. \n",
    "\n",
    "Below is a demo of `mlflow.pyfunc`, where it is used to define a simple model pipeline class that encompass a random forest model with a particular preprocessing step. To get a feel of how this pyfunc object is then integrated into the rest of the mlflow ecosystem, let's also go through the steps of training and serving the model including passing on custom configuration, capture model signature and python environment, and finally load and apply the model to make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "class RFWithPreprocess(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.rf_model = None\n",
    "        self.config = None\n",
    "\n",
    "    def load_context(self, context=None, config_path=None):\n",
    "        \"\"\"\n",
    "        When loading a pyfunc, this method runs automatically with the related\n",
    "        context.  This method is designed to perform the same functionality when\n",
    "        run in a notebook or a downstream operation (like a REST endpoint).\n",
    "\n",
    "        If the context object is provided, it will load the path to a config from\n",
    "        that object (this happens with mlflow.pyfunc.load_model() is called).\n",
    "        If the config_path argument is provided instead, it uses this argument\n",
    "        in order to load in the config.\n",
    "        \"\"\"\n",
    "        if context: # This block executes for server run\n",
    "            config_path = context.artifacts['config_path']\n",
    "        else: # This block executes for notebook run\n",
    "            pass\n",
    "\n",
    "        self.config = json.load(open(config_path))\n",
    "    \n",
    "    def preprocess_input(self, model_input):\n",
    "        \"\"\"\n",
    "        return preprocessed model input. \n",
    "        \"\"\"\n",
    "\n",
    "        processed_input = model_input.copy()\n",
    "        # put any desired logic here\n",
    "        processed_input.drop(processed_input.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        return processed_input\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        processed_model_input = self.preprocess_input(X_train.copy())\n",
    "        rf_model = RandomForestRegressor(**self.params)\n",
    "        rf_model.fit(processed_model_input, y_train)\n",
    "\n",
    "        self.rf_model = rf_model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        processed_model_input = self.preprocess_input(model_input.copy())\n",
    "        return self.rf_model.predict(processed_model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Log the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for demo\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "# Create a DataFrame for visualization (optional)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=X, columns=diabetes.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing context\n",
    "\n",
    "The `context` parameter is provided automatically by mlflow in downstream tools. This can be used to add custom dependent objecs such as models that are not easily serialized (e.g., `keras` models) or custom configurations files. \n",
    "\n",
    "Steps to provide a config file:\n",
    "* save out any file we want to load into the class\n",
    "* Create an artifact dictionary of key/value pairs where the value is the path to that object\n",
    "* When saving the model, all artifacts will be copied over into the same directory for downstream use\n",
    "\n",
    "\n",
    "In the example below, let's pass on some model hyperparameters into the config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 15,\n",
    "    'max_depth': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/02 22:31:44 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\ningw\\AppData\\Local\\Temp\\tmppuchnol_\\model, flavor: python_function), fall back to return ['cloudpickle==2.0.0']. Set logging level to DEBUG to see the full traceback.\n",
      "c:\\Users\\ningw\\anaconda3\\envs\\py38-modelling\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name = 'test') as run:\n",
    "    \n",
    "    model = RFWithPreprocess(params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        'test_pyfunc',\n",
    "        python_model = model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config_path': 'mlruns/data.json'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "config_path = \"mlruns/data.json\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "\n",
    "artifacts = {'config_path': config_path}\n",
    "print(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model config: {'n_estimators': 15, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "# This happens automatically in serving integrations\n",
    "model.load_context(config_path = config_path)\n",
    "print(\"model config:\", model.config)\n",
    "predictions = model.predict(context = None, model_input = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate model signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [0: double (required), 1: double (required), 2: double (required), 3: double (required), 4: double (required), 5: double (required), 6: double (required), 7: double (required), 8: double (required), 9: double (required)]\n",
       "outputs: \n",
       "  [Tensor('float64', (-1,))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "signature = infer_signature(X_test, predictions)\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture conda environment\n",
    "\n",
    "This is necessary because when we use `mlflow.sklearn`, we automatically log the apprropriate version of `sklearn`. With a `pyfunc`, we must manually construct our deployment environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channels': ['defaults'],\n",
       " 'dependencies': ['python=3.8.15',\n",
       "  'pip',\n",
       "  {'pip': ['mlflow', 'sciket-learn==1.2.0']}],\n",
       " 'name': 'sklearn_env'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import version_info\n",
    "import sklearn\n",
    "\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        f\"python={version_info.major}.{version_info.minor}.{version_info.micro}\",\n",
    "        \"pip\",\n",
    "        {\"pip\": [\"mlflow\",\n",
    "                 f\"sciket-learn=={sklearn.__version__}\"]\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"sklearn_env\"\n",
    "}\n",
    "\n",
    "conda_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log the model\n",
    "\n",
    "We can log the model with rich info such as artifacts, conda_env, signature and input_example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "# double-check env in respond to warning in the next cell, see backlog\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902c6abdf18a4ee5852d071eb9561266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/28 18:32:35 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - sciket-learn (current: uninstalled, required: sciket-learn==1.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name = 'test') as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        'rf_preprocessed_model',\n",
    "        python_model = model,\n",
    "        artifacts = artifacts,\n",
    "        conda_env=conda_env,\n",
    "        signature=signature,\n",
    "        input_example=X_test[:3]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Utilize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/28 18:32:36 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - sciket-learn (current: uninstalled, required: sciket-learn==1.2.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "mlflow_pyfunc_model_path = f\"runs:/{run.info.run_id}/rf_preprocessed_model\"\n",
    "loaded_preprocess_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model\n",
    "\n",
    "to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158.48896884, 184.32338111, 157.3486947 , 250.67946537,\n",
       "       116.10953609, 129.25752347, 248.23706751, 218.31714944,\n",
       "       145.43777053, 175.50507834, 109.77701145, 172.44423645,\n",
       "        90.35806064, 231.02801247, 106.28503907, 154.19536245,\n",
       "       229.13414973, 247.54295669, 181.75428992, 211.87610517,\n",
       "       187.58071778, 111.24837101,  82.73119571, 192.2444602 ,\n",
       "       148.18506314, 179.78699311, 172.81527653, 110.4966332 ,\n",
       "        82.73119571, 114.28501395, 168.95470798,  99.35855525,\n",
       "       162.76867799, 202.87625786, 152.05677875, 220.14202136,\n",
       "       120.39505122, 122.23399749, 170.92243273,  86.01504187,\n",
       "        82.73119571,  81.51166825, 152.6721596 , 145.65301484,\n",
       "       154.08324524,  92.94443125,  82.70940559, 112.48905089,\n",
       "        78.58980894, 177.53117506, 132.73170066,  86.0199772 ,\n",
       "       182.63527763, 100.08397662, 175.22945738, 162.00083005,\n",
       "       105.52205377, 205.63997098, 110.33266442, 111.82741378,\n",
       "       176.60377189, 178.64678837, 155.34659724,  96.90164203,\n",
       "       126.17653215, 211.66207362, 189.57538533, 169.95995965,\n",
       "       142.82797963, 143.36013334, 183.34579088, 181.95488621,\n",
       "       212.10790774, 108.0694351 ,  84.3233752 , 158.58696288,\n",
       "       215.79815697, 166.87847069, 179.53379898, 201.22130716,\n",
       "        94.4784982 , 123.59882627,  99.1128651 ,  92.42423054,\n",
       "        98.97635281,  89.66058509,  94.50165442,  88.27410709,\n",
       "       166.85390091])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_preprocess_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Model's Metadata\n",
    "\n",
    "One really cool thing about `pyfunc` object is that it is automatically loaded with its metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_estimators': 15, 'max_depth': 5}\n",
      "input example: {'data': [[0.04534098333546186, -0.044641636506989144, -0.006205954135807083, -0.015998975220305175, 0.12501870313429186, 0.1251981011367534, 0.019186997017453092, 0.03430885887772673, 0.03243232415655107, -0.005219804415300423], [0.09256398319871433, -0.044641636506989144, 0.0369065288194249, 0.0218723855140367, -0.0249601584096303, -0.016658152053905938, 0.0007788079970183853, -0.03949338287409329, -0.022516528376302174, -0.021788232074638245], [0.06350367559055897, 0.05068011873981862, -0.004050329988045492, -0.012556124244455912, 0.10300345740307394, 0.04878987646010685, 0.05600337505832251, -0.002592261998183278, 0.08449153066204618, -0.01764612515980379]]}\n"
     ]
    }
   ],
   "source": [
    "run_id = loaded_preprocess_model.metadata.run_id\n",
    "path = mlflow.artifacts.download_artifacts(run_id = run_id)\n",
    "params = json.load(open(f\"{path}/rf_preprocessed_model/artifacts/data.json\"))\n",
    "print(\"params:\", params)\n",
    "input_example = json.load(open(f\"{path}/rf_preprocessed_model/input_example.json\"))\n",
    "print(\"input example:\", input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backlog\n",
    "\n",
    "When logging the model with its conda environment, there is a warning saying sklearn is not installed in the current envionrment, which is not true. \n",
    "\n",
    "What's reassuring is that the conda_env did capture the correct module versions for the model, but the warnings are nonetheless annoying. Could this due to the notebook running in a virtual environment (the same happens when I am using either an anoconda or pipenv virtual env)? Note that this is not the case when similar commands are running in Databrick clusters. Will keep exploring and update any learning back here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Databricks-zutb1lv8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
